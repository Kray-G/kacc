# class Lexer

## Introduction

The class `Lexer` is a lexical analyzer class used by a parser generated by Kacc. See the following example, and you will find a usage of this class.

```javascript
/* Lexical analyzer */
var lexer = new Kacc.Lexer();
lexer.addSkip(/[ \t\r]+/);
lexer.addRule(/[_a-zA-Z][_a-zA-Z0-9]*/, TOKEN_IDENTIFIER);
lexer.addRule(/[0-9]+/, TOKEN_NUMBER) { &(value) => Integer.parseInt(value) };

/* Parser */
var vars = {};
var parser = new Kacc.Parser(lexer, {
    yyerror: &(msg)         => System.println(("ERROR! " + msg).red().bold()),
    setVar:  &(name, value) => vars[name] = value,
    getVar:  &(name)        => vars[name],
});
```

Basically it's 3 steps when you use it.

1. Instanciate the instance of `Lexer` class.
2. Set rules to the lexer instance.
3. Pass the lexer instance to the constructor of a Parser class when a parser is instanciated.

## Public Methods

### For Debug

#### debugOn(flags)

You can enable debug functions. Flags are below. Note that a flag is assigned to the lexer object, so you have to specify it as a property of the object.

- `lexer.DEBUG_STATE` ... Prints a current state on the console.
- `lexer.DEBUG_TOKEN` ... Prints a returned token number as integer on the console,
- `lexer.DEBUG_VALUE` ... Prints a value which will be passed to a parser.

Those values are a bit map value, so you can specify those with a bitwise-or operation, something like `lexer.DEBUG_STATE|lexer.DEBUG_TOKEN`. See the following example.

```javascript
lexer.debugOn(lexer.DEBUG_STATE|lexer.DEBUG_TOKEN|lexer.DEBUG_VALUE);
```

This is an example of dislaying all debug messages to console.

#### debugOff(flags)

You can disable debug functions. You can specify it with a bitwise-or operation to disable a specific flag that you want to make disable. See the following example.

```javascript
lexer.debugOff(lexer.DEBUG_STATE);
```

This is an example of disabling the message of the state.

### For Lexer Pattern

#### addSkip(pattern)

You can set the rule you want to skip as a rule of the `KACC_LEXER_STATE_INITIAL` state. The pattern should be a regular expression object. Below is the example of skipping white spaces.

```javascript
lexer.addSkip(/[ \t\r]+/);
```

This is same as below.

```javascript
lexer.addSkip(/[ \t\r]+/, KACC_LEXER_SKIP);
lexer.addStateSkip(KACC_LEXER_STATE_INITIAL, /[ \t\r]+/);
```

Please see also `addRule` and `addStateSkip` for details.

#### addRule(pattern, token, action)

You can set the rule you want to anaylze as lexer as a rule of the `INITIAL` state. The pattern should be a regular expression object, and if matched to the pattern, it will return the `token` value you specified.

The `action` can be omitted if unnecessary. If setting it, the value can be translated to something you want. For example, if it is a number, the lexer will take it as a string. That's why you can convert it to the integer value like this.

```javascript
lexer.addRule(/[0-9]+/, TOKEN_NUMBER) { &(value) => Integer.parseInt(value) };
```

In this case, the lexer will return `TOKEN_NUMBER` as a token, and the lexer will also set the integer value to `yylval.value` which will be used in a parser.

#### addKeyword(word, token)

This sets a keyword. The keyword means a single word and it will be a reserved word in almost all cases. For example, see below.

```javascript
lexer.addKeyword("if", TOKEN_IF);
lexer.addKeyword("while", TOKEN_WHILE);
```

When a keyword is found, the lexer will just return a token corresponding to the word.

#### addStateSkip(state, pattern)

This is like `addSkip`. The only difference is that you can specify the state. Therefore, the 2 examples below are a same meaning.

```javascript
lexer.addSkip(/[ \t\r]+/);
lexer.addStateSkip(KACC_LEXER_STATE_INITIAL, /[ \t\r]+/);
```

It means, the `addSkip` method is the special method for the state of `KACC_LEXER_STATE_INITIAL`.

#### addStateRule(state, pattern, token, action)

This is a specia method of `addRule`. This is similar to the relation between `addSkip` and `addStateSkip`. See below.

```javascript
lexer.addRule(/[_a-zA-Z][_a-zA-Z0-9]*/, TOKEN_IDENTIFIER);
lexer.addStateRule(KACC_LEXER_STATE_INITIAL, /[_a-zA-Z][_a-zA-Z0-9]*/, TOKEN_IDENTIFIER);
```

It means that the `addRule` method is the special method for the state of `KACC_LEXER_STATE_INITIAL` as well as `addSkip`.

#### addStateKeyword(state, word, token)

This is a specia method of `addKeyword`. This is similar to the relation between `addSkip` and `addStateSkip`. See below.

```javascript
lexer.addKeyword("if", TOKEN_IF);
lexer.addStateKeyword(KACC_LEXER_STATE_INITIAL, "if", TOKEN_IF);
```

It means that the `addKeyword` method is the special method for the state of `KACC_LEXER_STATE_INITIAL` as well as `addSkip`.

#### setState(state), $(state)

The lexer has a state internally. This is used when you want to change the state. The default state is `KACC_LEXER_STATE_INITIAL` which means `"INITIAL"`, and the state should be a string. You can set rules per state, and you can change the state during parsing.

See below about how to use it. You should pass the `this` object as a second argument to the callback function if you want to use this method. `@$` is also available instead of `@setState`.

```javascript
lexer.addRule(/\/\*/) { &(value, this)
    ++@commentCount;
    return @$('COMMENT', KACC_LEXER_SKIP);
        // The state will be changed to 'COMMENT',
        //  and returns KACC_LEXER_SKIP as a token.
};
lexer.addStateRule('COMMENT', /\*\/|\/\*|./) { &(value, this)
    if (value.value == '/*') {
        ++@commentCount;
    }
    if (value.value == '*/') {
        if (--@commentCount == 0) {
            return @$(KACC_LEXER_STATE_INITIAL, KACC_LEXER_SKIP);
                // The state will be changed to 'INITIAL',
                //  and returns KACC_LEXER_SKIP as a token.
        }
    }
    return KACC_LEXER_SKIP;
        // Otherwise, returns KACC_LEXER_SKIP as a token.
};
```

### For Parser

**DO NOT USE** these methods because these methods should be used only by a parser.

#### reset(text)

This is used when a parser will start parsing.

#### yylex(yylval)

This is used when a parser will get a next token.
